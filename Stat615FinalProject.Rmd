---
title: "Final Project"
author: "Akash Agrawal Bejarano & Johnson Odejide"
date: "05/06/2023"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, include = T, warning = F, message = F)
```


## 1 

```{r}
library(tidyverse)
library(dplyr)
library(ggplot2)
dataset <- read.csv("expenses.csv")

dataset <- dataset %>% 
  mutate(sex = as.factor(sex),
         smoker = as.factor(smoker),
         region = as.factor(region))
```


The dataset contains information regarding healthcare expenses with a total of 1338 observations. It has a total of 7 variables, 4 quantitative and 3 being categorical. The quantitative variables are Age, BMI (body mass index), children (how many children do you have), charges (cost). The categorical variables are Sex, Smoker, and Region. 

## 2

```{r}
library(corrplot)

dataset %>% 
  keep(is.numeric) -> dataset_quantitative

  cor(dataset_quantitative) -> dataset.cor
  corrplot.mixed(dataset.cor, upper = 'pie',lower='number')
  
qqnorm(dataset$age)
qqline(dataset$age)

qqnorm(dataset$bmi)
qqline(dataset$bmi)

qqnorm(dataset$children)
qqline(dataset$children)

qqnorm(dataset$charges)
qqline(dataset$charges)

levels(dataset$sex)
levels(dataset$smoker)
levels(dataset$region)
```


## 3 

```{r}
fullmodel <- lm(charges ~ ., data = dataset)
```

## 4

```{r}

df <- data.frame(dataset_quantitative[, c("charges", "age", "bmi", "children")])

datarows <- nrow(df)

y_mat <- as.matrix(df)[, 1]
x1 <- df[, 2]
x2 <- df[, 3]
x3 <- df[, 4]

Ym <- matrix(y_mat, ncol = 1, byrow = T)


y_int <- data.frame(matrix(nrow = datarows, ncol = 1))

for(i in seq(1:datarows)){
  y_int[i, 1] = 1
}

df <- data_frame(y_int, x1, x2, x3)


Xm <- cbind(rep(1, datarows), as.matrix(df[, 2]), as.matrix(df[, 3]), as.matrix(df[, 4]))


# Lets find the transpose of matrix Xm
t(Xm) -> transposeXm

# The product of Xm and the transpose of Xm
  transposeXm%*%Xm-> ProDuct1

# Inverse of the matrix * transpose * Y
solve(ProDuct1)%*%transposeXm%*%Ym
  

# Calculate the intercept and slope  
solve(ProDuct1)%*%transposeXm%*%Ym -> interceptandslope
```

## 5
```{r}
summary(fullmodel)
```

Adjusted R^2 value = 0.7494 

From the output summary above we can see that Age, BMI, children, smokeryes, region southeast, region southwest are all significant. while sexmale, region northwest are insignificant at the 0.05 significance level. 

## 6

```{r}
model.fit <- lm(charges ~ ., dataset_quantitative)
# summary(model.fit)

confint(model.fit)

# -6916.24 + 239.99age + 332.08bmi + 542.85children

age_upper <- 239.99 + 1.961744 * 22.29
age_lower <- 239.99 - 1.961744 * 22.29

bmi_upper <- 332.08 + 1.961744 * 51.31
bmi_lower <- 332.08 - 1.961744 * 51.31

# d.data <- tibble(X, Y)
conf.95 <- qt(p=.025, df=1334, lower.tail = FALSE)


conf.int.age <- cbind("Lower CI (Age)" = age_lower, "Upper CI (Age)" = age_upper)
conf.int.bmi <- cbind("Lower CI (BMI)" = bmi_lower, "Upper CI (BMI)" = bmi_upper)

```
```{r}
conf.int.age
```
```{r}
conf.int.bmi
```



## 7

Since sex and region both contained an insignificant effect on charges, we choose to remove these from the reduced model so that we only use significant predictors. 

```{r}
reducedmodel <- lm(charges ~ age + bmi + children + smoker, data = dataset)
summary(reducedmodel)
summary(fullmodel)
```
```{r}
anova(reducedmodel, fullmodel)
```

The anova test is not significant at the 0.05 level. Hence, we will use the reduced model.

## 8

```{r}
library(tree)

tree.model <- tree(charges ~ ., dataset,
                   mindev = 0.005)

tree.model

summary(tree.model)

plot(tree.model)
text(tree.model, pretty = 0)
```
We have used the **regression tree** here.

The regression finds which of the independent variables (in this case - smoker, bmi, age) divides the observations more accurately into two portions, and at which value of that variable, and then assigns a predicted value for each of the two portions equal to their respective response value mean. It then takes each of the two portions and further subdivides them, either with the same variable or the other variable, whichever separates the portion better. For instance, we see that the variable `smoker` is divided into two - those who smoke and those who do not. It then further uses the variable `age` to divide up those who do not smoke into two - those who are less than 43 years and those who are more etc.

To determine the number of splittings to do, we use a parameter called **mindev**. The lower the mindev the more the trees grow. If we change the mindev to something larger than we used here, it will make the tree smaller than this.


## 9

**4 - 5 sentences**

The regression tree clearly revealed that those who smoke pay more on healthcare than those who do not smoke. Furthermore, if they have a BMI that is greater than 30.01 and are older than 41 years old, they spend the most on healthcare. From the tree, we also see that those who do not smoke but are over 51 years old tend to spend more on healthcare than those who are younger than 51 years and this is true because the body gets weaker and the immune systems too get weaker.

Interpretations:

**children**

**smoker**

A smoker spends much more on healthcare expenses. 

















